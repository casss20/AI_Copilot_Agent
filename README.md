# ğŸš€ AI Copilot Agent

![AI Copilot Agent](https://img.shields.io/badge/version-1.0.0-blue)
![Python](https://img.shields.io/badge/Python-3.12-green)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-teal)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28.1-red)
![Ollama](https://img.shields.io/badge/Ollama-Deepseek--coder-black)

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [System Architecture](#system-architecture)
- [Features](#features)
- [Technology Stack](#technology-stack)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [API Endpoints](#api-endpoints)
- [Dependencies](#dependencies)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

**AI Copilot Agent** is a powerful programming assistant that helps developers with coding questions, debugging, and code examples. It leverages local LLMs (like Deepseek-Coder) through Ollama, with optional support for cloud-based models (OpenAI GPT-4, Claude). The system features conversation memory, rate limiting, specialized copilots, and a beautiful Streamlit interface.

## ğŸ— System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI COPILOT AGENT                              â”‚
â”‚                      Programming Assistant                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              ğŸ§‘ğŸ’» USER
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND (Streamlit 1.28.1)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    ğŸ¤– AI Copilot                             â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚  Ask me something about programming:                â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  [How do I sort a list in Python?]                  â”‚    â”‚    â”‚
â”‚  â”‚  â”‚                                                     â”‚    â”‚    â”‚
â”‚  â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚    â”‚    â”‚
â”‚  â”‚  â”‚              â”‚ Send ğŸ“¤ â”‚                             â”‚    â”‚    â”‚
â”‚  â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚    â”‚    â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚    â”‚
â”‚  â”‚  â”‚              ğŸ’¬ CONVERSATION HISTORY                 â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  ğŸ‘¤ You (14:30): How do I sort in Python?   â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚                                              â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  ğŸ¤– Assistant (14:31):                       â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  Use the sort() method or sorted() function: â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚                                              â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  ğŸ“‹ Copy â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚          â”‚ my_list = [3,1,4,2] â”‚           â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚          â”‚ my_list.sort()      â”‚           â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ HTTP POST (JSON) :8000
                                 â”‚ {"prompt": "How do I sort..."}
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND API (FastAPI 0.104.1)                     â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                     MIDDLEWARE LAYER                          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚    â”‚
â”‚  â”‚  â”‚   CORS      â”‚  â”‚    Rate     â”‚  â”‚    Auth     â”‚          â”‚    â”‚
â”‚  â”‚  â”‚  Middleware â”‚  â”‚  Limiting   â”‚  â”‚ (JWT/PyJWT) â”‚          â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚    â”‚
â”‚  â”‚                                                              â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚                 ENDPOINTS LAYER                       â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  POST /copilot        POST /copilot/python  â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  POST /copilot/js      POST /copilot/debug  â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  GET  /health          GET  /history/{id}   â”‚    â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â”‚                                                              â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚                 SERVICE LAYER                         â”‚    â”‚    â”‚
â”‚  â”‚  â”‚                                                      â”‚    â”‚    â”‚
â”‚  â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚    â”‚    â”‚
â”‚  â”‚  â”‚    â”‚  Conversationâ”‚    â”‚    Cache     â”‚            â”‚    â”‚    â”‚
â”‚  â”‚  â”‚    â”‚    Manager   â”‚    â”‚   Manager    â”‚            â”‚    â”‚    â”‚
â”‚  â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚    â”‚    â”‚
â”‚  â”‚  â”‚                                                      â”‚    â”‚    â”‚
â”‚  â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚    â”‚    â”‚
â”‚  â”‚  â”‚    â”‚    Rate      â”‚    â”‚   Response   â”‚            â”‚    â”‚    â”‚
â”‚  â”‚  â”‚    â”‚   Limiter    â”‚    â”‚  Formatter   â”‚            â”‚    â”‚    â”‚
â”‚  â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â”‚                                                              â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚                  AI MODEL LAYER                       â”‚    â”‚    â”‚
â”‚  â”‚  â”‚                                                      â”‚    â”‚    â”‚
â”‚  â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚    â”‚    â”‚
â”‚  â”‚  â”‚    â”‚           Model Selector                â”‚      â”‚    â”‚    â”‚
â”‚  â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚    â”‚    â”‚
â”‚  â”‚  â”‚           â”‚            â”‚            â”‚               â”‚    â”‚    â”‚
â”‚  â”‚  â”‚           â–¼            â–¼            â–¼               â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚   Local     â”‚ â”‚   OpenAI    â”‚ â”‚   Claude    â”‚   â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚   Models    â”‚ â”‚   Models    â”‚ â”‚   Models    â”‚   â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚ Deepseek-   â”‚ â”‚  GPT-4      â”‚ â”‚  Claude-3   â”‚   â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â”‚ coder       â”‚ â”‚  GPT-3.5    â”‚ â”‚  Opus       â”‚   â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                 â”‚                                    â”‚
â”‚                                 â–¼                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                    â”‚             â”‚
                    â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     IN-MEMORY STORAGE    â”‚  â”‚    OLLAMA (LOCAL)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ Conversation      â”‚  â”‚  â”‚  â”‚ â€¢ deepseek-coder    â”‚  â”‚
â”‚  â”‚   History           â”‚  â”‚  â”‚  â”‚ â€¢ Cache             â”‚  â”‚
â”‚  â”‚ â€¢ Cache             â”‚  â”‚  â”‚  â”‚ â€¢ Rate Limiting     â”‚  â”‚
â”‚  â”‚ â€¢ Rate Limiting     â”‚  â”‚  â”‚  â”‚   Data              â”‚  â”‚
â”‚  â”‚   Data              â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

- **ğŸ¤– Multiple AI Models**: Support for local (Deepseek-coder, Llama) and cloud (GPT-4, Claude) models
- **ğŸ’¬ Conversation Memory**: Remembers context across multiple questions
- **ğŸš€ Specialized Copilots**: Python expert, JavaScript expert, Debugging assistant
- **âš¡ Rate Limiting**: Prevents API abuse (60 requests/minute)
- **ğŸ’¾ Response Caching**: Reduces redundant API calls
- **ğŸ“ Code Highlighting**: Beautiful syntax highlighting in responses
- **ğŸ“‹ Copy to Clipboard**: One-click code copying
- **ğŸ” Authentication**: API key-based security
- **ğŸ“Š Session Management**: Multiple conversation sessions
- **ğŸ©º Health Monitoring**: Built-in health checks


![alt text](image.png)

## ğŸ›  Technology Stack

### Backend
| Technology | Version | Purpose |
|------------|---------|---------|
| **FastAPI** | 0.104.1 | High-performance web framework for APIs |
| **Uvicorn** | 0.24.0 | ASGI server for FastAPI |
| **Python-dotenv** | 1.0.0 | Environment variable management |
| **Nest-asyncio** | 1.5.8 | Async support in Jupyter notebooks |
| **PyJWT** | 2.10.1 | JWT authentication |
| **Python-multipart** | 0.0.9 | Form data parsing |
| **Passlib** | 1.7.4 | Password hashing |
| **Bcrypt** | 4.0.1 | Password encryption |
| **HTTPX** | 0.27.2 | Async HTTP client for API calls |

### AI Models
| Technology | Version | Purpose |
|------------|---------|---------|
| **OpenAI** | 2.20.0 | GPT-4 and GPT-3.5 integration |
| **Anthropic** | 0.7.7 | Claude AI integration |
| **Ollama** | Latest | Local model management |
| **Deepseek-coder** | Latest | Code-specialized local LLM |

### Frontend
| Technology | Version | Purpose |
|------------|---------|---------|
| **Streamlit** | 1.28.1 | Rapid UI development |
| **Requests** | 2.31.0 | HTTP client for API calls |

### Optional (for production)
| Technology | Purpose |
|------------|---------|
| **Redis** | Production-grade caching and rate limiting |
| **Docker** | Containerization |
| **PostgreSQL** | Persistent storage |

## ğŸ“ Project Structure

```
ai-copilot-agent/
â”‚
â”œâ”€â”€ ğŸ“‚ backend/
â”‚   â”œâ”€â”€ ğŸ“„ main.py                 # FastAPI application entry point
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ ğŸ“„ .env                    # Environment variables
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ models/
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”œâ”€â”€ ğŸ“„ openai_model.py     # OpenAI GPT integration
â”‚       â”œâ”€â”€ ğŸ“„ claude_model.py     # Claude AI integration
â”‚       â””â”€â”€ ğŸ“„ local_model.py      # Ollama local models
â”‚
â”œâ”€â”€ ğŸ“‚ frontend/
â”‚   â”œâ”€â”€ ğŸ“„ app.py                  # Streamlit UI application
â”‚   â””â”€â”€ ğŸ“„ requirements.txt        # Frontend dependencies
â”‚
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # Docker configuration
â”œâ”€â”€ ğŸ“„ README.md                    # Project documentation
â””â”€â”€ ğŸ“„ .gitignore                   # Git ignore file
```

## ğŸ“¦ Installation

### Prerequisites
- Python 3.12+
- Ollama (for local models)
- Git

### Step 1: Clone the Repository
```bash
git clone https://github.com/yourusername/ai-copilot-agent.git
cd ai-copilot-agent
```

### Step 2: Set Up Backend
```bash
# Navigate to backend folder
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On Mac/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Step 3: Set Up Frontend
```bash
# Open new terminal, navigate to frontend folder
cd frontend

# Install frontend dependencies
pip install -r requirements.txt
```

### Step 4: Install and Configure Ollama
```bash
# Download and install Ollama from https://ollama.ai

# Pull code-specific models
ollama pull deepseek-coder:latest
ollama pull codellama

# Verify installation
ollama list
```

### Step 5: Configure Environment Variables
Create `.env` file in the backend folder:
```env
# API Keys (optional - for cloud models)
OPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here

# Local Model Configuration
LOCAL_MODEL_NAME=deepseek-coder:latest
OLLAMA_URL=http://localhost:11434
MODEL_TEMPERATURE=0.2
MODEL_MAX_TOKENS=2048
MODEL_CONTEXT_LENGTH=8192

# Rate Limiting
RATE_LIMIT=60
```

## ğŸš€ Usage

### Start the Backend Server
```bash
# Terminal 1
cd backend
venv\Scripts\activate  # or source venv/bin/activate on Mac/Linux
python main.py
# Server runs at http://localhost:8000
```

### Start Ollama (if not running)
```bash
# Terminal 2
ollama serve
```

### Start the Frontend
```bash
# Terminal 3
cd frontend
streamlit run app.py
# UI available at http://localhost:8501
```

### Using the Application

1. **Open browser** at `http://localhost:8501`
2. **Select model** from sidebar:
   - `local` - Deepseek-coder (default)
   - `gpt4` - OpenAI GPT-4 (requires API key)
   - `gpt35` - OpenAI GPT-3.5
   - `claude` - Claude AI
3. **Choose copilot type**:
   - General Programming
   - Python Expert
   - JavaScript Expert
   - Debugging Expert
4. **Ask programming questions**!
5. **Copy code** with one click

## ğŸŒ API Endpoints

| Endpoint | Method | Description | Auth Required |
|----------|--------|-------------|---------------|
| `/copilot` | POST | General programming assistant | Yes |
| `/copilot/python` | POST | Python specialist | Yes |
| `/copilot/javascript` | POST | JavaScript specialist | Yes |
| `/copilot/debug` | POST | Debugging specialist | Yes |
| `/health` | GET | Health check | No |
| `/history/{session_id}` | GET | Get conversation history | Yes |
| `/history/{session_id}` | DELETE | Clear conversation history | Yes |

### API Request Example
```json
POST /copilot
{
    "prompt": "How do I sort a list in Python?",
    "session_id": "user123",
    "model": "local"
}
```

### API Response Example
```json
{
    "response": "Use the sort() method or sorted() function...",
    "cached": false,
    "model": "local",
    "copilot_type": "general",
    "session_id": "user123"
}
```

## ğŸ“š Dependencies Deep Dive

### Why These Dependencies?

#### Backend Framework
- **FastAPI**: Chosen for its automatic OpenAPI documentation, high performance (on par with Node.js), and built-in validation using Pydantic
- **Uvicorn**: Lightning-fast ASGI server that supports async/await

#### AI Integration
- **OpenAI 2.20.0**: Latest SDK with full support for GPT-4 and GPT-3.5 Turbo, includes streaming capabilities
- **Anthropic 0.7.7**: Official Claude SDK with support for Claude 3 models
- **Ollama**: Zero-configuration local model management, no API keys needed

#### Security
- **PyJWT 2.10.1**: Industry standard for stateless authentication
- **Passlib + Bcrypt**: Secure password hashing with multiple rounds of encryption

#### Performance
- **Redis 5.0.1**: (Optional) In-memory data store for caching and rate limiting
- **HTTPX**: Async HTTP client that supports both HTTP/1.1 and HTTP/2

#### Development
- **Python-dotenv**: Secure environment variable management
- **Nest-asyncio**: Enables running asyncio in Jupyter notebooks

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 style guide
- Add tests for new features
- Update documentation
- Use type hints

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenAI for GPT models
- Anthropic for Claude
- Ollama team for local model management
- Deepseek for the excellent coder model
- FastAPI and Streamlit communities

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

---

**Made with â¤ï¸ for developers everywhere**
